{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "EMG_AntagonisticPairs_WithKinematics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neurologic/NeurophysiologyModules/blob/main/EMG_AntagonisticPairs_WithKinematics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "850eb426-07d8-4407-82f1-f163a2c960b6"
      },
      "source": [
        "<a id=\"one\"></a>\n",
        "\n",
        "# By collecting data for this lab and thoughtfully working through the analysis, you will learn more about what it means for neural activity to be coordinated, and how activity in the motor system relates to movement in the world. \n",
        "Some of the terms and analytic techniques that you will be using:\n",
        "- correlation\n",
        "- EMG\n",
        "- amplitude envelope\n",
        "- dimension/dimensionality\n",
        "- variance\n",
        "- orthogonal\n",
        "- kinematics\n",
        "\n",
        "### Throughout the notebook, you will plot raw data and results of analysis.\n",
        "- You can interact with the plots by zooming in and panning. <br>\n",
        "- You can make the plot bigger or smaller by dragging its bottom right corner (gray triangle). Note that when it gets smaller the axis labels might disappear.\n",
        "- You can save the current plot view at any time by hitting the \"save\" icon - it will save to your Downloads folder. <br>\n",
        "\n",
        "## Part I. Initialize notebook.\n",
        "As you now know, Python's Jupyter Lab notebooks are a way to combine executable code, code outputs, and text into one connected file. They run using a <b>'kernel'</b>, which is the thing that executes your code. It is what connects the notebook (as you see it) with the part of your computer, or the DataHub computers, that runs code. When you 'run'/'execute' code cells, the kernel does what the code tells it to, for example: importing software packages, importing data, plotting data, calculating correlation between signals, etc. Instructions to 'run' code cells are contained in green boxes within these 'markdown' (text) cells. Make sure to execute the cells in order throughout the notebook without skipping over cells. \n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Run the cell below to import necessary packages and set up the coding environment.</div>"
      ],
      "id": "850eb426-07d8-4407-82f1-f163a2c960b6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63fd8fa5-0914-4d1a-87bd-9d20927aedca"
      },
      "source": [
        "# No need to edit anything in this code cell\n",
        "#################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from scipy.signal import hilbert,medfilt,resample\n",
        "from sklearn.decomposition import PCA\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import matplotlib.animation as animation\n",
        "%matplotlib widget\n",
        "# https://towardsdatascience.com/how-to-produce-interactive-matplotlib-plots-in-jupyter-environment-1e4329d71651\n",
        "\n",
        "fs = 100\n",
        "fs_vid = 30\n",
        "\n",
        "def get_bodypart_speed(df_vid,d,new_name):\n",
        "    dd = np.diff(df_vid[d].values)\n",
        "    fs_ = 1/np.mean(np.diff(df_vid['time']))\n",
        "    speed = np.concatenate([[0],dd/(1/fs_)])\n",
        "    filtert = int(0.15*fs_)\n",
        "    speed = scipy.ndimage.gaussian_filter(speed,filtert)\n",
        "    df_vid[new_name] = (speed - np.mean(speed))/np.std(speed)\n",
        "    return df_vid\n",
        "\n",
        "def get_bodypart_speed_absolute(df_vid,x,y,new_name):\n",
        "    dx = np.diff(df_vid[x].values)\n",
        "    dy = np.diff(df_vid[y].values)\n",
        "    dpos = np.sqrt(dx**2 + dy**2)\n",
        "    fs_ = 1/np.mean(np.diff(df_vid['time']))\n",
        "    speed = np.concatenate([[0],dpos/(1/fs_)])\n",
        "    filtert = int(0.15*fs_)\n",
        "    speed = scipy.ndimage.gaussian_filter(speed,filtert)\n",
        "    df_vid[new_name] = (speed - np.mean(speed))/np.std(speed)\n",
        "    return df_vid\n",
        "\n",
        "def get_bone_speed(df_vid,bone,new_name):\n",
        "    dd = np.diff(df_vid[bone].values)\n",
        "    fs_ = 1/np.mean(np.diff(df_vid['time']))\n",
        "    speed = np.concatenate([[0],dd/(1/fs_)])\n",
        "    filtert = int(0.15*fs_)\n",
        "    speed = scipy.ndimage.gaussian_filter(speed,filtert)\n",
        "    df_vid[new_name] = (speed - np.mean(speed))/np.std(speed)\n",
        "    return df_vid"
      ],
      "id": "63fd8fa5-0914-4d1a-87bd-9d20927aedca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7db5fd4d-fe22-4e61-ac4c-66858c5a47b5"
      },
      "source": [
        "### Edit the code cell below with the appropriate information, then play/execute the cell\n",
        "> all file names and paths need to be in quotations, ***if you are on a windows operating system computer, you need an \"r\" before the first quote of a filepath***\n",
        "- **folderpath** is the path to your muscle data (.csv file) that has simultaneous recording of two muscles as well as the tracking data (.h5 files) from the video analysis. \n",
        "- **emg_file** = the \".csv\" data file that has simultaneous recording of two muscles.\n",
        "- **joints_file** = the \"_filtered.h5\" file from video tracking analysis\n",
        "- **bones_file** the \"_skeleton.h5\" file from video tracking analysis\n",
        "- **videotimestamps_file** = the \".csv\" file that has timestamps from the video camera input during recording\n",
        "- **channels** = which arduino channels provided your amplified muscle data to bonsai.\n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below (after entering all of the filepaths and filenames requested) will tell the computer where to look for your data.</div>"
      ],
      "id": "7db5fd4d-fe22-4e61-ac4c-66858c5a47b5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6c3147c-62f2-4ad0-b4a1-a50b280283c0"
      },
      "source": [
        "folderpath = \"/Users/kperks/mnt/OneDrive - wesleyan.edu/Teaching/Neurophysiology/Data/EMG_Tracking/20211031/\"\n",
        "\n",
        "emg_file = \"analoginput_zip2021-10-31T13_05_29.csv\"\n",
        "joints_file = 'video2021-10-31T13_05_30DLC_resnet101_EMG_Tracking_ZooInitializedNov3shuffle1_20000_filtered.h5'\n",
        "bones_file = 'video2021-10-31T13_05_30DLC_resnet101_EMG_Tracking_ZooInitializedNov3shuffle1_20000_skeleton.h5'\n",
        "videotimestamps_file = \"video_timestamps2021-10-31T13_05_29.csv\"\n",
        "\n",
        "channels = ['1','5'] #channels recorded\n",
        "\n",
        "\n",
        "# No need to edit anything below this line\n",
        "#################################\n",
        "\n",
        "emg_path = Path(folderpath) / emg_file\n",
        "joints_path = Path(folderpath) / joints_file\n",
        "bones_path = Path(folderpath) / bones_file\n",
        "video_path = Path(folderpath) / videotimestamps_file\n",
        "\n",
        "print('completed at ' + str(datetime.datetime.now()))"
      ],
      "id": "a6c3147c-62f2-4ad0-b4a1-a50b280283c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53da42e9-918d-488a-8c14-4116a8ad9fb2"
      },
      "source": [
        "<a id=\"two\"></a>\n",
        "## Part II. Import raw EMG data and process the signal.\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below actually imports the raw EMG data and formats it in a way that can be plotted.</div>"
      ],
      "id": "53da42e9-918d-488a-8c14-4116a8ad9fb2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7600b10d-bba8-4831-bf59-520cb56d5362"
      },
      "source": [
        "#%% import data\n",
        "df_analog_ = pd.read_csv(emg_path.expanduser().resolve(), sep=',')\n",
        "\n",
        "# rename headers as input channels\n",
        "for i,h in enumerate(list(df_analog_.columns)[:-1]):\n",
        "    df_analog_.rename(columns={h : str(i)},inplace=True)\n",
        "    \n",
        "# the last column is timestamps    \n",
        "df_analog_.rename(columns={list(df_analog_.columns)[-1] : 'time'},inplace=True)\n",
        "\n",
        "# reformat 'Time' to start at t0 = 0 and be units of seconds\n",
        "# xtime = (df_analog['Time']-df_analog['Time'].iloc[0])/1000\n",
        "# reformat 'Time' to be units of seconds\n",
        "xtime = (df_analog_['time'])/1000\n",
        "df_analog_['time'] = xtime\n",
        "x = np.linspace(df_analog_['time'].iloc[0],df_analog_['time'].iloc[-1],\n",
        "                int((df_analog_['time'].iloc[-1]-df_analog_['time'].iloc[0])*fs))\n",
        "df_mat = [df_analog_.loc[np.max(df_analog_[df_analog_['time']<=x_].index)].values for x_ in x]\n",
        "df_analog = pd.DataFrame(df_mat,columns = df_analog_.columns)\n",
        "df_analog = df_analog.loc[:,channels]\n",
        "df_analog['time']=x-x[0]"
      ],
      "id": "7600b10d-bba8-4831-bf59-520cb56d5362",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c80eb80-1d17-47bb-81a8-023bf0c2476d"
      },
      "source": [
        "### Plot the raw EMG signal from each muscle\n",
        "> The amplitude units are in Volts, but the absolute amplitude of the signals are not important for the analyses of this data that we will do for this lab. In the next step, you will be obtaining the \"amplitude envelope\" of this raw signal, which discards absolute Voltage information anyway. <br>\n",
        "<br>\n",
        "> The \"baseline\" of each channels is offset from each other so that they are not visually overlaid - the baseline voltage of the recording on each channel was actually zero. \n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below plots the raw EMG signal across time from each channel recorded.</div>"
      ],
      "id": "0c80eb80-1d17-47bb-81a8-023bf0c2476d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8290362d-2e74-4fd3-acd3-e4ef54467a38"
      },
      "source": [
        "# No need to edit this code cell\n",
        "################################\n",
        "hfig,axs = plt.subplots(1)\n",
        "axs.set_xlabel('seconds')\n",
        "axs.set_ylabel('amplitude')\n",
        "axs.set_yticklabels([])\n",
        "axs.plot(df_analog['time'],df_analog[channels[0]].values,linewidth = 2,color = 'blue')\n",
        "axs.plot(df_analog['time'],df_analog[channels[1]].values + np.median(df_analog[channels[0]].values),linewidth = 2,color = 'orange')\n"
      ],
      "id": "8290362d-2e74-4fd3-acd3-e4ef54467a38",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0fe1688-8482-4072-9f38-0436e3cbcf42"
      },
      "source": [
        "### Look at the raw data that you just plotted. \n",
        "#### Pick a time window to analyze that has decently stereotyped patterned behavior and enter it in the code cell below\n",
        "- **start** = the time in your recording when stereotyped patterned behavior became clear.\n",
        "- **stop** = the time in your recording when stereotyped patterned behavior stopped.\n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Edit the code cell below to define the region of your recording used for analysis. Then run the cell.</div>"
      ],
      "id": "a0fe1688-8482-4072-9f38-0436e3cbcf42"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccb7f4d2-384b-4161-8c57-9d37750c91bc"
      },
      "source": [
        "start = 11.79\n",
        "stop = 47.06\n",
        "\n",
        "\n",
        "# No need to edit below this line\n",
        "################################\n",
        "print('all set - analysis domain defined')"
      ],
      "id": "ccb7f4d2-384b-4161-8c57-9d37750c91bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d1f1545-2f25-4bfe-be34-1dfb7ca3444e"
      },
      "source": [
        "### Process the raw EMG signal into a rectified, smoothed \"amplitude envelope\"\n",
        "> This is a type of *signal processing*. You have already encountered this type of signal processing when you analyzed the extracellular cockroach data that you collected earlier this semester. Remind yourself of what this does to the raw signal that you recorded. The result here is a processed signal that we will refer to as the *amplitude envelope* of the EMG activity. \n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Run the cell below to process the raw EMG signal and get its \"envelope\". You will also get a plot of the EMG envelope. You do not need to edit anything in the code cell.</div>"
      ],
      "id": "0d1f1545-2f25-4bfe-be34-1dfb7ca3444e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04522a80-6411-4c81-b24e-358987ac64dc"
      },
      "source": [
        "# No need to edit this code cell\n",
        "################################\n",
        "\n",
        "# Use rectfication and gaussian smoothing on EMG to get mean-centered rate\n",
        "df_rate = pd.DataFrame({})\n",
        "filtert = int(0.05*fs)\n",
        "for h in list(df_analog.columns)[:-1]: # rename headers as input channels\n",
        "    y = df_analog[h] - np.mean(df_analog[h])\n",
        "    y = np.abs(y) #takes the absolute value of \n",
        "    y = scipy.ndimage.gaussian_filter(y,filtert)\n",
        "    df_rate[h] = y\n",
        "# df_rate = df_rate.subtract(df_rate.mean())\n",
        "df_rate =(df_rate - df_rate.mean()) / df_rate.std()\n",
        "df_rate['time']=df_analog['time']\n",
        "df_rate = df_rate[((df_rate['time']>start) & (df_rate['time']<stop))]\n",
        "\n",
        "hfig,ax = plt.subplots(1)\n",
        "ax.set_xlabel('seconds')\n",
        "ax.set_ylabel('amplitude')\n",
        "ax.set_yticklabels([])\n",
        "ax.plot(df_rate['time'],df_rate[channels[0]].values,linewidth = 2,color = 'blue')\n",
        "ax.plot(df_rate['time'],df_rate[channels[1]].values,linewidth = 2,color = 'orange')"
      ],
      "id": "04522a80-6411-4c81-b24e-358987ac64dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f7e282-b954-42bd-8ea2-b5edb134ec99"
      },
      "source": [
        "### Think about how you would qualitatively describe the relationship between the two muscle signals. As part of your answer, include a statement about correlation. \n",
        "> Essentially, correlation is the measure of how two or more variables are related to one another. https://en.wikipedia.org/wiki/Correlation\n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below creates two figures. One is a scatter plot of the EMG envelope of one muscle against the other muscle. Think about how this is a way to visualize *correlation*. The second is a *correlation matrix* table that provides the mathematical correlation values between the two signals.</div> "
      ],
      "id": "84f7e282-b954-42bd-8ea2-b5edb134ec99"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0387e96e-32ec-461c-a242-f7070d9356aa"
      },
      "source": [
        "# No need to edit this code cell\n",
        "################################\n",
        "print('correlation matrix:')\n",
        "p_corr = df_rate.drop('time',axis=1).corr()\n",
        "# hfig, ax = plt.subplots(1)\n",
        "# sns.heatmap(p_corr, annot=True)\n",
        "display(p_corr)\n",
        "\n",
        "hfig,axs = plt.subplots(1)\n",
        "axs.scatter(df_rate[channels[0]],df_rate[channels[1]],color = 'black',alpha = 0.1);\n",
        "axs.set_ylabel('amplitude (a.u.) of your second EMG channel')\n",
        "axs.set_xlabel('amplitude (a.u.) of your first EMG channel');\n"
      ],
      "id": "0387e96e-32ec-461c-a242-f7070d9356aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d494468-1f12-4f71-9196-9a77e1633a38"
      },
      "source": [
        "## Now let's examine how motor system activity relates to movement kinematics."
      ],
      "id": "0d494468-1f12-4f71-9196-9a77e1633a38"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1f1365e-440e-4ec9-b2c7-ad3b7b23086e"
      },
      "source": [
        "<a id=\"three\"></a>\n",
        "## Part III. Import tracking data from the simultaneously recorded video\n",
        "### Edit the code cell below with the appropriate information, then play/execute the cell\n",
        "- **bodyparts** is the list of body parts that are relevant to your analysis of the movement/muscle activity. Each body part must be in quotes. Body parts separated by commas.\n",
        "- **bones** = is the list of bones that are relevant to your analysis of the movement/muscle activity. Each bone must be in quotes. Bones separated by commas.\n",
        "<br>\n",
        "\n",
        "#### Possible body parts: (1 = right, 2 = left)\n",
        "- wrist1(or 2), elbow1(or 2), shoulder1(or 2), hip1(or 2), knee1(or 2), ankle1(or 2), chin, forehead.\n",
        "\n",
        "#### Possible bones: \n",
        "- refer to the skeleton that you created for your video tracking in Collaboratory notebook. \n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below will import and collect tracking data for the body parts and bones that you specify.</div>"
      ],
      "id": "e1f1365e-440e-4ec9-b2c7-ad3b7b23086e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4652623b-15c0-4a44-82a6-b329fee3fc0e"
      },
      "source": [
        "bodyparts = ['wrist1','shoulder1','shoulder2']\n",
        "bones = ['wrist1_elbow1']\n",
        "\n",
        "\n",
        "\n",
        "# No need to edit below this line\n",
        "################################\n",
        "\n",
        "df_vid = pd.read_hdf(joints_path) # import data from body parts _filtered.h5\n",
        "df_vid = df_vid[df_vid.columns[0][0]]\n",
        "df_vid.columns = df_vid.T.index.map('_'.join)\n",
        "coords = ['_x','_y']\n",
        "# filter by coordinates or liklihood\n",
        "coords = [any(keep in ele for keep in coords) for ele in list(df_vid.columns)]\n",
        "# filter by bodyparts\n",
        "bodyparts = [any(keep in ele for keep in bodyparts) for ele in list(df_vid.columns)]\n",
        "df_vid_bodyparts = df_vid.loc[:,(np.asarray(coords) & np.asarray(bodyparts))]\n",
        "\n",
        "df_vid = pd.read_hdf(bones_path) # import data from bones _skeleton.h5\n",
        "df_vid.columns = df_vid.T.index.map('_'.join)\n",
        "coords = ['orientation']\n",
        "# filter by coordinates or liklihood\n",
        "coords = [any(keep in ele for keep in coords) for ele in list(df_vid.columns)]\n",
        "# filter by bodyparts\n",
        "bones = [any(keep in ele for keep in bones) for ele in list(df_vid.columns)]\n",
        "df_vid_bones = df_vid.loc[:,(np.asarray(coords) & np.asarray(bones))]\n",
        "\n",
        "df_vid = df_vid_bones.join(df_vid_bodyparts) # combine bones and bodyparts\n",
        "df_vid =(df_vid - df_vid.mean()) / df_vid.std() # mean subtract and normalize by std\n",
        "df_vid['time'] = df_vid.index.values / fs_vid # create time column\n",
        "df_vid = df_vid[((df_vid['time']>start) & (df_vid['time']<stop))] # select start:stop section\n",
        "\n",
        "print('body parts and bones that you can now analyze for kinematics:')\n",
        "print(list(df_vid.keys()))\n",
        "print('')\n",
        "print('sample of table with positions of body parts and orientations of bones')\n",
        "display(df_vid.head())\n",
        "\n"
      ],
      "id": "4652623b-15c0-4a44-82a6-b329fee3fc0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0974ab7-4585-41ad-9e4c-e9af1120c9a7"
      },
      "source": [
        "<a id=\"four\"></a>\n",
        "## Part IV. Calculate some basic movement kinematics - speed\n",
        "### By editing and running each of the next three code cells (A, B, and C) you can calculate the speed of particular features that you think are important for understanding the movement\n",
        "> You can do the next 3 code cells in any order. To calculate another kinematic parameter, just change the x, y, or bone inputs and re-run the cell. <br>\n",
        "<br>\n",
        "> After running each code cell, the updated data table will be displayed along with a new list of all of the movement parameters that you can analyze."
      ],
      "id": "e0974ab7-4585-41ad-9e4c-e9af1120c9a7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a22ab2a7-f9fa-4010-b3dc-ed70e3eb9c79"
      },
      "source": [
        "<div class=\"alert alert-success\"><b>A:</b> Running the cell below gets the absolute speed of a body part (no directional information). Supply the name of the _x and _y components for a specific body part.  Also provide the name you want to call this new calculated parameter.</div>"
      ],
      "id": "a22ab2a7-f9fa-4010-b3dc-ed70e3eb9c79"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43b98b99-0eda-45a9-b96c-8bb95c63dcab"
      },
      "source": [
        "x = 'wrist1_x'\n",
        "y = 'wrist1_y'\n",
        "new_name = 'wrist1_speed'\n",
        "\n",
        "\n",
        "# No need to edit below this line\n",
        "################################\n",
        "df_vid = get_bodypart_speed_absolute(df_vid,x,y,new_name)\n",
        "display(df_vid.drop('time',axis=1).head())\n",
        "print('body parts, bones, and kinematics that you can now examine and compare to muscle activity:')\n",
        "print(list(df_vid.drop('time',axis=1).keys()))"
      ],
      "id": "43b98b99-0eda-45a9-b96c-8bb95c63dcab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7a51c87-f8b4-4d35-8d70-fe9e64b4023c"
      },
      "source": [
        "<div class=\"alert alert-success\"><b>B:</b> Running the cell below gets the speed of a body part in either the x or y direction. Provide the name of a body part appended by either _x or _y. Also provide the name you want to call this new calculated parameter.</div>"
      ],
      "id": "e7a51c87-f8b4-4d35-8d70-fe9e64b4023c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960233e8-f503-4dc3-9f06-1b8fc152b0b4"
      },
      "source": [
        "d = 'wrist1_y'\n",
        "new_name = 'wrist1_yspeed'\n",
        "\n",
        "\n",
        "# No need to edit below this line\n",
        "################################\n",
        "df_vid = get_bodypart_speed(df_vid,d,new_name)\n",
        "display(df_vid.drop('time',axis=1).head())\n",
        "print('body parts, bones, and kinematics that you can now examine and compare to muscle activity:')\n",
        "print(list(df_vid.drop('time',axis=1).keys()))"
      ],
      "id": "960233e8-f503-4dc3-9f06-1b8fc152b0b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48955f53-050b-4e40-bbe6-1ecaa4eebec8"
      },
      "source": [
        "<div class=\"alert alert-success\"><b>C:</b> Running the cell below gets the speed of a bone (the rate of change of its orientation). Provide the name of a bone (with suffix _orientation). Also provide the name you want to call this new calculated parameter.</div></div>"
      ],
      "id": "48955f53-050b-4e40-bbe6-1ecaa4eebec8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a041a713-2b4b-4566-a236-aa416128769c"
      },
      "source": [
        "bone = 'wrist1_elbow1_orientation'\n",
        "new_name = 'wrist_elbow_speed'\n",
        "\n",
        "\n",
        "# No need to edit below this line\n",
        "################################\n",
        "df_vid = get_bone_speed(df_vid,bone,new_name)\n",
        "display(df_vid.drop('time',axis=1).head())\n",
        "print('body parts, bones, and kinematics that you can now examine and compare to muscle activity:')\n",
        "print(list(df_vid.drop('time',axis=1).keys()))"
      ],
      "id": "a041a713-2b4b-4566-a236-aa416128769c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18fd6801-4ff5-45e2-87c2-f697f8b93afb"
      },
      "source": [
        "<a id=\"five\"></a>\n",
        "## Part V. Plot bodyparts, bones, or kinematics that you want to visually compare to muscle activity\n",
        "### Edit the code cell below with the appropriate information, then play/execute the cell\n",
        "- **kinematics_to_plot** is the list of kinematics or body part positions, or bone orientations that you want to plot in comparison to muscle activity (the plots will all be overlaid)\n",
        "- **colors_to_plot** = Choose what color you want each kinematic parameter to be plotted as (this will enable you to keep track of which parameter is which in the plot). Do not use \"blue\" or \"orange\" (these are the colors that the EMG envelopes will be plotted in).\n",
        "  - A list of possible colors to use can be found here: https://xkcd.com/color/rgb/\n",
        "\n",
        "### You can change these lists and re-plot to look at different variables.\n",
        "\n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> After editing the 'kinematics_to_plot' and 'colors_to_plot' variables, run the cell below to overlay all of these variables on the same plot.</div>"
      ],
      "id": "18fd6801-4ff5-45e2-87c2-f697f8b93afb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a04ffaee-fe1a-444b-a3b3-c247815d57a4"
      },
      "source": [
        "kinematics_to_plot = ['wrist_elbow_speed','wrist1_speed','wrist1_yspeed']\n",
        "colors_to_plot = ['green','aqua','lime']\n",
        "\n",
        "\n",
        "# No need to edit below this line\n",
        "################################\n",
        "hfig,ax = plt.subplots(1)\n",
        "for k,c in zip(kinematics_to_plot,colors_to_plot):\n",
        "    ax.plot(df_vid['time'],df_vid[k],linewidth = 2,color = sns.xkcd_rgb[c],label = k,alpha = 0.75)\n",
        "ax.plot(df_rate['time'],df_rate[channels[0]].values,linewidth = 2,color = sns.xkcd_rgb['blue'],alpha = 0.75,label = 'EMG channel' + str(channels[0]))\n",
        "ax.plot(df_rate['time'],df_rate[channels[1]].values,linewidth = 2,color = sns.xkcd_rgb['orange'],alpha = 0.75,label = 'EMG channel' + str(channels[1]))\n",
        "plt.legend();"
      ],
      "id": "a04ffaee-fe1a-444b-a3b3-c247815d57a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "8308e25c-a976-4aa2-9a77-7f20ea762ab0"
      },
      "source": [
        "### Think about how you would qualitatively describe the relationship between the two muscle signals and the kinematic variables (and the relationship among kinematic variables). As part of your answer, include statements about correlation. "
      ],
      "id": "8308e25c-a976-4aa2-9a77-7f20ea762ab0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9385d4a-54a7-4484-97e9-97e33418d93a"
      },
      "source": [
        "<a id=\"six\"></a>\n",
        "## Part VI. You might be thinking... ***THIS IS A LOT TO KEEP TRACK OF!***\n",
        "### In this section, we will start to implement \"*Dimensionality Reduction*\" - a technique commonly used in neuroscience to make sense of \"BIG DATA.\"\n",
        "> You will read and learn more about this in the paper from Mark Churchlan's lab. But let's start to get a feel for it.\n",
        "\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Run the cell below to perform a \"Principal Components Analysis\" (PCA) on the ALL of the tracking and kinematics data that you have used to quantif the movement.</div>"
      ],
      "id": "b9385d4a-54a7-4484-97e9-97e33418d93a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c161daf-ee75-4c3e-85db-005ec5654ca3"
      },
      "source": [
        "# No need to edit this code cell the first time you run in\n",
        "################################\n",
        "df = df_vid.drop('time',axis=1)\n",
        "df =(df - df.mean()) / df.std()\n",
        "n_dim = 10\n",
        "n_components=np.min([n_dim,df.shape[1]]) # if try to take more components than have channels, use amount of channels\n",
        "print('You quantified your movement into ' + str(len(df.columns)) + ' positional and kinematic variables')\n",
        "pca = PCA(n_components=n_components)\n",
        "pca.fit(df)\n",
        "df_pca = pd.DataFrame(pca.transform(df), columns=['PC%i' % i for i in range(n_components)], index=df.index)\n",
        "print('Your movement has now been transformed into ' + str(n_components) + ' principle components.')"
      ],
      "id": "2c161daf-ee75-4c3e-85db-005ec5654ca3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee67086d-af9e-4abf-a4c9-bed6912ac68f"
      },
      "source": [
        "<div class=\"alert alert-success\"><b>Task:</b> Run the cell below to overlay the first two principle components (orthogonal dimensions) of the result. No need to edit the cell.</div>"
      ],
      "id": "ee67086d-af9e-4abf-a4c9-bed6912ac68f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebad08ce-dc96-4684-b226-9be78082d38b"
      },
      "source": [
        "hfig,ax = plt.subplots(1)\n",
        "ax.set_xlabel('seconds')\n",
        "ax.set_ylabel('PC units')\n",
        "ax.set_yticklabels([])\n",
        "ax.plot(df_vid['time'],df_pca['PC0'],label = 'PC0',alpha = 0.75)\n",
        "ax.plot(df_vid['time'],df_pca['PC1'],label = 'PC1',alpha = 0.75)\n",
        "plt.legend();"
      ],
      "id": "ebad08ce-dc96-4684-b226-9be78082d38b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a4e458e-977c-47c4-a33b-4bd98c4b8a1d"
      },
      "source": [
        "## PC0 is the first principal component of the movement, PC1 is the second, etc.\n",
        "> Importantly, these principal components are *independent* of each other. They are *orthogonal* dimensions of the movement.\n",
        "### Go back and edit the last cell (the one that made a plot of PC0 versus PC1) so that you can also see a plot of PC2. \n",
        "- find the line that says ```ax.plot(df_vid['time'],df_pca['PC0'],label = 'PC0')```\n",
        "- copy that line (ctrl + C on the keyboard), make a new line, and paste it (ctrl + V on the keyboard).\n",
        "- change 'PC0' to 'PC2' everywhere in your pasted line that you see it. \n",
        "- re-run the code cell and see how your plot changed! <br>\n",
        "\n",
        "### OK, ONE MORE! This time, go back and edit the last cell again so that you can also see a plot of the last principal component.   \n",
        "- find the line that you just added and edited. It should currently say ```ax.plot(df_vid['time'],df_pca['PC2'],label = 'PC2', alpha = 0.75)```\n",
        "- go back to the output of the last code cell and see how many principle components were used to describe your movement. \n",
        "- change 'PC2' to the last principle component (this will be the number of total principle components minus 1). \n",
        "- re-run the code cell and see how your plot changed!"
      ],
      "id": "0a4e458e-977c-47c4-a33b-4bd98c4b8a1d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "305ab5f2-459e-4cea-8fd2-c5b91319fda9"
      },
      "source": [
        "## What's going on here? \n",
        "> Think about some of the differences that you notice between the first couple of principle components and the last couple of principle components. The following plot should quantitatively correlate with some of the things that you are qualitatively noticing. \n",
        "<div class=\"alert alert-success\"><b>Task:</b> Run the cell below to see a scatter plot showing how much of the variance in the data is explained in each principal component.</div>"
      ],
      "id": "305ab5f2-459e-4cea-8fd2-c5b91319fda9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96b33c7d-d2ce-49e1-90ca-c8f1720ff686"
      },
      "source": [
        "# No need to edit this code cell\n",
        "################################\n",
        "hfig,ax = plt.subplots(1)\n",
        "ax.scatter(df_pca.columns,pca.explained_variance_ratio_,color='black',s=100)\n",
        "ax.set_ylabel('Explained Variance')\n",
        "ax.set_xlabel('Principal Components')\n",
        "ax.set_ylim(-0.05,1.05)"
      ],
      "id": "96b33c7d-d2ce-49e1-90ca-c8f1720ff686",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18cbf5c8-7ce1-453f-b909-f1746fb6175b"
      },
      "source": [
        "## Dimensionality reduction techniques, such as principle components analysis (PCA), enable us to represent and quantify high-dimensional things (like neural populations and movements) in a new *space*. \n",
        "> These PCA spaces are in some ways abstract. But in other ways, the abstract space is actually the essence of the neural activity or movement. \n",
        "### What is the \"shape\" of this movement in the space defined by the PCA dimensions?\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below plots the first principal component against the second.</div>"
      ],
      "id": "18cbf5c8-7ce1-453f-b909-f1746fb6175b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5115a69-c60a-4add-bfe5-afd5ecd3a630"
      },
      "source": [
        "# No need to edit this code cell\n",
        "################################\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.set_xlabel('Principal Component 1')\n",
        "ax.set_ylabel('Principal Component 2')\n",
        "ax.plot(df_pca['PC0'],df_pca['PC1'],color = 'black',alpha = 0.75,linewidth=2);"
      ],
      "id": "f5115a69-c60a-4add-bfe5-afd5ecd3a630",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "315a10cd-daa0-4956-9a4f-fb9642274db5"
      },
      "source": [
        "### But how does the movement evolve over time? (ie. where is time in the plot?)\n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below animates the movement over time through this \"latent\" space - the space defined by the principal components.</div>"
      ],
      "id": "315a10cd-daa0-4956-9a4f-fb9642274db5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70c0b1b0-c3f3-44ad-83ad-502a200cc2ba"
      },
      "source": [
        "# No need to edit this code cell\n",
        "################################\n",
        "\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.plot(df_pca['PC0'],df_pca['PC1'],color = 'black',alpha = 0.5,linewidth=2)\n",
        "t, = ax.plot(df_pca['PC0'].values[0], df_pca['PC1'].values[0],color = 'red',marker='.',markersize = 20)\n",
        "\n",
        "def animate(i):\n",
        "    ax.plot(df_pca['PC0'].values[i], df_pca['PC1'].values[i],color = 'red',marker='.',markersize = 15,zorder=3,alpha = 0.25)\n",
        "    \n",
        "ani = animation.FuncAnimation(\n",
        "    fig, animate, frames = len(df_pca),interval=10, repeat = False)\n",
        "plt.show()"
      ],
      "id": "70c0b1b0-c3f3-44ad-83ad-502a200cc2ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cca5dba-23af-4e63-a5ac-5c2e731f3d87"
      },
      "source": [
        "### And how does the movement look in the 3-dimensional space defined by the PCA? \n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below plots the movement in the first three principle components. You can rotate the plot around in 3D.</div>"
      ],
      "id": "2cca5dba-23af-4e63-a5ac-5c2e731f3d87"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd3cf627-cbb3-44e6-8ee6-8c168a58fb04"
      },
      "source": [
        "# No need to edit this code cell\n",
        "################################\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.plot3D(df_pca['PC0'],df_pca['PC1'],df_pca['PC2'],color = 'black',alpha = 0.5,linewidth=2)\n",
        "ax.set_xlabel('PC0')\n",
        "ax.set_ylabel('PC1')\n",
        "ax.set_zlabel('PC2')"
      ],
      "id": "fd3cf627-cbb3-44e6-8ee6-8c168a58fb04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e6ee43e-6862-412a-816b-37577191677a"
      },
      "source": [
        "### And how does the movement in PCA space compare to the muscle activity in muscle space? \n",
        "<div class=\"alert alert-success\"><b>Task:</b> Running the cell below plots the activity of muscle 1 against muscle 2.</div>"
      ],
      "id": "4e6ee43e-6862-412a-816b-37577191677a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98816d37-30c0-43fa-a267-3df22f28bb0f"
      },
      "source": [
        "# No need to edit this code cell\n",
        "################################\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.set_xlabel('muscle activity 1')\n",
        "ax.set_ylabel('muscle activity 2')\n",
        "ax.plot(df_rate[channels[0]],df_rate[channels[1]],color = 'black',alpha = 0.75,linewidth=2);"
      ],
      "id": "98816d37-30c0-43fa-a267-3df22f28bb0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "731b7d37-09bd-4c37-935d-0c6cd65784ae"
      },
      "source": [
        "# Take-home assignmnent\n",
        "\n",
        "## Review: Why/What dimensionality reduction?\n",
        "\"Describing a complex signal, such as a visual scene or a pattern of neural activity, in terms of just a few summarizing features is called dimensionality reduction\" (Pang et al 2016). This is a tool that has successfully been used to achieve one of the main goals in neuroscience -- to objectively quantify what the brain represents and computes. BUT this tool can be daunting, 'mathy,' and abstract when first encountered. This module and its analyses are designed to help you scaffold your intuition for what dimensionality reduction does and its power as an analytic tool to generate representations of stimuli, movements, and brain activity that are concise, complete, and informative about the workings of the nervous system, without being biased by arbitrary experimental choices. Dimensionality reduction (and specifically Principle Component Analysis introduced in this lab) provides an entry point into principled mathematical techniques that let us discover these representations directly from experimental data, a key step to developing rich yet comprehensible models for brain function.\n",
        "\n",
        "I like the following example from Pang et al (2016) \"Dimensionality reduction in neuroscience.\"\n",
        "\"An example of dimensionality reduction is color vision. Light hitting the eye has intensity in a wide range of frequencies. While a spectrophotometer would provide a complete description of the light beam in terms of its power spectrum across all frequencies, our retina has only three kinds of color sensor, the L, M and S cone types (corresponding to long, medium, and short wavelengths). All we can know about the incoming light is given to us by the activation of those three sensors: because of the unique frequency absorption properties of each cone type, the activation of a given cone type is a function of a weighted sum of the light’s intensities at different frequencies. Thus, our color perception is a three-dimensional representation of the original, infinite-dimensional spectrogram that specifies the light’s intensity at every frequency.\"\n",
        "\n",
        "## Questions to answer: Use the prompts and questions to create the following 6 figures. Use a separate document to answer the following questions in a separate document (Fig 2, 5 and 6 do not need separate text). Answer the questions in the format of a concise paragraph (rather than a bullet point list of answers). Consolidate, summarize, interpret. Refer to panels in the figures you create (for example as Figure 1A) in order to visualize/show what you write in words.\n",
        "\n",
        "### Figure 1. *Correlations*\n",
        "Pick one experimental condition.\n",
        "- Based on the data that you recorded (not the movement that you know you did), describe the pattern of muscle activity that you observed.  \n",
        "- Interpret the correlation value between the activity in the two muscles you recorded. \n",
        "\n",
        "### Figure 2. *Movement Tracking Results*\n",
        "Use the same experimental condition as in Figure 1.\n",
        "- Take a screenshot of your labelled video. \n",
        "- Annotate the body parts and bones that you analyzed in order to relate movement to muscle activity.\n",
        "- Label the muscles that you recorded (and placement of electrodes)\n",
        "\n",
        "### Figure 3. *Dimensionality Reduction*\n",
        "Use the same experimental condition as in Figure 1.\n",
        "- Describe the relationship between the movement kinematics you calculated and the muscle activity. Summarize patterns and categorize similar variables together rather than describing every pairwise comparison explicitly. \n",
        "- How would you describe the way the movement looks in PCA space? In theory, think about whether you could use kinematic variables to make a plot that looks similar. If you did this, how many kinematic variables would you be able to incorporate in your plot?\n",
        "- Describe the relationship between muscle activity and the first several PCAs (however many are useful based on your analysis). \n",
        "- What is the difference between low number PCAs and high number PCAs? How would you describe the reason for this trend to someone who has even less understanding of PCA than you do?\n",
        "\n",
        "### Figure 4. *Data interpretation*\n",
        "Analyze both of your experimental conditions to compare.\n",
        "- Compare the movement in PCA space for your two different conditions.\n",
        "- Compare the muscle activity for your two different conditions.\n",
        "- How did the relationship between muscle activity and movement change? Why? You can use what you learned from the papers that we read for this module as background to help you describe. \n",
        "- Figure 2 from Russo et al (2018) shows a dissociation between movement kinematics and muscle activity. How does Figure 2 show this? Did your task comparison achieve this?\n",
        "\n",
        "### Figure 5. *Connections to Primary Literature*\n",
        "- Examine Figure 1 of the Russo et al (2018) paper and answer the following. Annotate the Figure to identify the following elements. Any additional information can be included in the legend. \n",
        "  - Where is the trial-averaged neural activity?\n",
        "  - What is the onset of a trial in this experiment?\n",
        "  - Where is the baseline activity of the neuron depicted?\n",
        "  - Where is an example individual trial of neural activity depicted? \n",
        "  - Panel H is \"rectified and smoothed\" muscle activity while F shows raw muscle activity (but zoomed out). Based on the average in H and the raw EMG data that you recorded and visualized, draw what you think the raw EMG voltage trace from one trial looks like for the example muscle shown.\n",
        "\n",
        "### Figure 6. *Connections to Primary Literature*\n",
        "- Recreate Figure 4, Panels A, B, C, and D from your data.\n",
        "- Use the legend from the paper as a template to help you write your legend."
      ],
      "id": "731b7d37-09bd-4c37-935d-0c6cd65784ae"
    }
  ]
}